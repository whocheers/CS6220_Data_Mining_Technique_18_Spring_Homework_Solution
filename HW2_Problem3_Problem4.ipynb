{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.5842403   3.6109329 ]\n",
      " [ 8.25532046  5.12825222]]\n",
      "(6000, 2)\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "[[ 3.62795109  0.4059141 ]\n",
      " [ 6.67554898  1.9710692 ]\n",
      " [ 2.10181757  6.13741452]]\n",
      "(6000, 3)\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "This is for 2 Gaussian:\n",
      "Gaussian 0, mean matrix [ 3.03043786  3.04882617] and covariance matrix [[ 1.07266452  0.02245989]\n",
      " [ 0.02245989  2.9103095 ]]\n",
      "Gaussian 1, mean matrix [ 7.03092943  3.99329205] and covariance matrix [[ 0.9451349   0.48072411]\n",
      " [ 0.48072411  0.98661324]]\n",
      "This is for 3 Gaussian:\n",
      "Gaussian 0, mean matrix [ 3.11564032  2.38595739] and covariance matrix [[ 1.00352732  0.09619581]\n",
      " [ 0.09619581  2.28080539]]\n",
      "Gaussian 1, mean matrix [ 7.0139545   3.98485373] and covariance matrix [[ 0.97332791  0.49427545]\n",
      " [ 0.49427545  0.99778653]]\n",
      "Gaussian 2, mean matrix [ 2.8269699   3.98269921] and covariance matrix [[ 0.97736951  0.18618389]\n",
      " [ 0.18618389  2.37051071]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import multivariate_normal\n",
    "from random import choices\n",
    "from numpy import linalg as LA\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This part is previous wrong initialization making each element in the weight Matrix the same and then \n",
    "\"\"\"\n",
    "# def weight_initialize(data_array, k):\n",
    "#     # data_array is N X M data array (Matrix)\n",
    "#     # get the len of data array(i.e., N) and its dimension(i.e., M)\n",
    "#     len_data = len(data_array)\n",
    "#     dimen_data = len(data_array[0])\n",
    "    \n",
    "#     # created a weight matrix N X K and set each elements into 0\n",
    "#     # source: https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html\n",
    "#     weightMat = np.zeros([len_data, k])\n",
    "    \n",
    "#     # initialize the weight Matrix and for each data point, the weight[i][k]\n",
    "#     # refer the probability of point i belonging into Gaussian distribution k\n",
    "#     # set each into equal probability\n",
    "#     for i in range(len_data): # for each data point\n",
    "#         for j in range(k):\n",
    "#             weightMat[i][j] = float(1.0)/float(k)\n",
    "#             ## weightMat[i][k] = float(1.0)/float(k)\n",
    "#     print(weightMat.shape)\n",
    "#     print(weightMat[:5])\n",
    "    \n",
    "#     return weightMat\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This part is correct initialization, for each data point i, the element which refers to the index of the \n",
    "smallest distance between this data point and all the K Gaussians(likewise the K centriods in k-means algorithms), \n",
    "is set into 1, namely, the probablity of data point i belonging to a certain gaussian (the smallest distance) is\n",
    "100% initially\n",
    "\"\"\"\n",
    "\n",
    "def weight_initialize(data_array, k):\n",
    "    # data_array is N X M data array (Matrix)\n",
    "    # get the len of data array(i.e., N) and its dimension(i.e., M)\n",
    "    len_data = len(data_array)\n",
    "    dimen_data = len(data_array[0])\n",
    "    \n",
    "    # created a weight matrix N X K and set each elements into 0\n",
    "    # source: https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html\n",
    "    weightMat = np.zeros([len_data, k])\n",
    "    \n",
    "    #randomly pick k data out of the array as the initial gaussians  \n",
    "    #source: https://docs.python.org/3/library/random.html\n",
    "    K_chosen = choices(range(len_data), k = k) ## a list\n",
    "    gaussians_initial= data_array[K_chosen]\n",
    "    \n",
    "    print(gaussians_initial)\n",
    "    \n",
    "    for i in range(len_data):\n",
    "        #define a list storing the distance of between each point and the gaussian's center\n",
    "        distance = np.zeros(k)\n",
    "        for j in range(k):\n",
    "            \n",
    "            ## get the 2-norm distance between the data point i and the gaussian center j\n",
    "            ## https://docs.scipy.org/doc/numpy-1.9.3/reference/generated/numpy.linalg.norm.html\n",
    "#             print(data_array[i, :] - gaussians_initial[j, :])\n",
    "            tt = LA.norm(data_array[i, :] - gaussians_initial[j, :]) \n",
    "#             print(tt)\n",
    "            distance[j] = tt\n",
    "            #distance[j] = LA.norm(data_array[i, :] - gaussians_initial[j, :]) \n",
    "        ## return the index of the smallest distance, i.e., the closest gaussian\n",
    "        # source : https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html    \n",
    "        index_closest = np.argsort(distance)[0]\n",
    "        weightMat[i][index_closest] = 1.0\n",
    "        \n",
    "    print(weightMat.shape)\n",
    "    print(weightMat[:5])\n",
    "        \n",
    "    return weightMat\n",
    "            \n",
    "\n",
    "# When get weightMat from weight_initialize() function, for the first time we also\n",
    "# need to get the initial mean and convariance by calling the M_step and then\n",
    "# further we can enter the iteration loop\n",
    "def M_step(data_array, weightMat, k):\n",
    "    \n",
    "    # data_array is N X M data array (Matrix)\n",
    "    # get the len of data array(i.e., N) and its dimension(i.e., M)\n",
    "    len_data = len(data_array)\n",
    "    dimen_data = len(data_array[0])\n",
    "#     print(k, dimen_data)\n",
    "    \n",
    "    ## initiate the mean matrix and the convariance matrix into 0\n",
    "     ## meanMat is a K X M matrix; \n",
    "     ##  covMat is a list of M X M matrix (K Matrix elements)\n",
    "    meanMat = np.zeros([k, dimen_data])\n",
    "    \n",
    "    covMat = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        covMat.append(np.zeros([dimen_data, dimen_data]))\n",
    "    ## a question: why [covMat.append(np.zeros([dimen_data,dimen_data])) for i in range(k)] failed to work??\n",
    "    \n",
    "    \"\"\"\n",
    "    calculate the mean Matrix and convriance Matrix here\n",
    "    \"\"\"\n",
    "    \n",
    "    ## here is the tempt mean\n",
    "    for j in range(len_data):\n",
    "        for t in range(k):\n",
    "            meanMat[t] += weightMat[j][t]*data_array[j] \n",
    "    # add the weight of each gaussian(i.e., cluster) together, here we need add elements of each colums together  \n",
    "    ##https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html\n",
    "    weight_gaussian = np.sum(weightMat, axis=0) \n",
    "#     print(\"??\")\n",
    "#     print(weight_gaussian)\n",
    "#     print(\"end\")\n",
    "    ## calculate the final mean Matrix\n",
    "    for i in range(k):\n",
    "        meanMat[i] = meanMat[i]/weight_gaussian[i]\n",
    "    \n",
    "    ## here is to get the tempt convirance\n",
    "    for i in range(len_data):\n",
    "        for j in range(k):\n",
    "            for m in range(dimen_data):\n",
    "                for n in range(dimen_data):\n",
    "                    covMat[j][m][n] += weightMat[i][j]*(data_array[i][m] - meanMat[j][m])*(data_array[i][n] - meanMat[j][n])\n",
    "    \n",
    "    \"\"\" bad: invalid syntax\n",
    "    ## here is to get the tempt convirance\n",
    "    for i in range(len_data):\n",
    "        for j in range(k):\n",
    "            [covMat[j][m][n] += weightMat[i][j]*(data_array[i][m] - meanMat[j][m])*(data_array[i][n] - meanMat[j][n]) for m in range(dimen_data) for n in range(dimen_data)]\n",
    "    \"\"\"\n",
    "    \n",
    "    ## calculate the final covirance Matrix\n",
    "    \n",
    "    for i in range(k):\n",
    "        ## covMat[i] = float(covMat[i])/float(weight_gaussian[i]) is wrong as only length-1 arrays can be converted to Python scalars\n",
    "        covMat[i] = covMat[i]/weight_gaussian[i]\n",
    "        \n",
    "    \n",
    "    return meanMat, covMat\n",
    "\n",
    "\n",
    "## Here the E_step is the return the new Weight Matrix\n",
    "\n",
    "def E_step(data_array, k, meanMat, covMat, weightMat_old):\n",
    "    \n",
    "    # data_array is N X M data array (Matrix)\n",
    "    # get the len of data array(i.e., N) and its dimension(i.e., M)\n",
    "    len_data = len(data_array)\n",
    "    dimen_data = len(data_array[0])\n",
    "    \n",
    "    # add the weight of each gaussian(i.e., cluster) together, here we need add elements of each colums together  \n",
    "    ##https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html\n",
    "    weight_gaussian = np.sum(weightMat_old, axis=0)\n",
    "    \n",
    "    ## before calculate the new weight Matrix we initialize it into 0\n",
    "    weightMat_new = np.zeros([len_data, k])\n",
    "    \n",
    "    for i in range(len_data):\n",
    "        for j in range(k):\n",
    "            # get the probablity by using the multivariate normal pdf\n",
    "            ## https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.multivariate_normal.html\n",
    "            pro = multivariate_normal.pdf(data_array[i], meanMat[j], covMat[j])\n",
    "            ## the tempt weightMat_new\n",
    "            weightMat_new[i][j] = pro*weight_gaussian[j]\n",
    "            \n",
    "        ## here is the final weightMat_new\n",
    "        weightMat_new[i] = weightMat_new[i]/np.sum(weightMat_new[i])\n",
    "        \n",
    "    return weightMat_new\n",
    "    \n",
    "    \n",
    "\n",
    "def GMM(data_array, k, iteration):\n",
    "    \n",
    "    weightMat_old = weight_initialize(data_array, k)\n",
    "    \n",
    "    while iteration>1:\n",
    "        iteration -=1\n",
    "        \n",
    "#         print(iteration)\n",
    "#         print(\"The weightMat_old is :\", weightMat_old)\n",
    "        \n",
    "        meanMat, covMat = M_step(data_array, weightMat_old, k)     \n",
    "        \n",
    "        \n",
    "#         print(meanMat)\n",
    "#         print(\"####\")\n",
    "#         print(covMat)\n",
    "#         print(\"##\")\n",
    "        \n",
    "        weightMat_new = E_step(data_array, k, meanMat, covMat, weightMat_old)\n",
    "#         print(iteration)\n",
    "#         print(\"The weightMat_new is :\", weightMat_new)\n",
    "        \n",
    "        weightMat_old = weightMat_new\n",
    "        \n",
    "#         print(weightMat_old)\n",
    "        \n",
    "    return meanMat, covMat\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    input_path1 = \"/Users/deshenghu/Dropbox/Dataset_CS6220/2gaussian.txt\"\n",
    "    input_path2 = \"/Users/deshenghu/Dropbox/Dataset_CS6220/3gaussian.txt\"\n",
    "    ## source: https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html\n",
    "    data1 = np.loadtxt(input_path1)\n",
    "    data2 = np.loadtxt(input_path2)\n",
    "    #print(data[-1:])\n",
    "    meanMat1, covMat1 = GMM(data1, 2, 25)\n",
    "    meanMat2, covMat2 = GMM(data2, 3, 80)\n",
    "    print(\"This is for 2 Gaussian:\")\n",
    "    for i in range(2):\n",
    "        print(\"Gaussian {}, mean matrix {} and covariance matrix {}\".format(i, meanMat1[i], covMat1[i]))\n",
    "        \n",
    "    print(\"This is for 3 Gaussian:\")\n",
    "    for i in range(3):\n",
    "        print(\"Gaussian {}, mean matrix {} and covariance matrix {}\".format(i, meanMat2[i], covMat2[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path1 = \"/Users/deshenghu/Dropbox/Dataset_CS6220/2gaussian.txt\"\n",
    "data = np.loadtxt(input_path1)\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "##The “mnist_train_fashion.csv” is downloaded from webpage of this link : https://www.kaggle.com/zalando-research/fashionmnist\n",
    "## here we only use the training data set for running the program\n",
    "\n",
    "# data_array_fashion is to store the training data\n",
    "data_array_fashion = []\n",
    "with open(\"/Users/deshenghu/Dropbox/Dataset_CS6220/mnist_train_fashion.csv\") as t:\n",
    "    #read csv file using csv.reader()\n",
    "    #source : https://docs.python.org/3/library/csv.html\n",
    "    reader = csv.reader(t)\n",
    "    for row in reader:\n",
    "        data_array_fashion.append(row)\n",
    "        \n",
    "\n",
    "# get the lables of the training data, which is the first element of each row\n",
    "data_fashion_lable = [row[0] for row in data_array_fashion]\n",
    "\n",
    "# delete the lable which is the first element of each row\n",
    "for i in range(len(data_array_fashion)):\n",
    "    del data_array_fashion[i][0]\n",
    "    \n",
    "data_fashion_tempt =  np.array(data_array_fashion)\n",
    "# because each element (\"number\") in the array is str and thus need to be converted\n",
    "data_fashion_list = [list(map(int, data_fashion_tempt[j])) for j in range(len(data_fashion_tempt))]\n",
    "\n",
    "data_fashion_training = np.matrix(data_fashion_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-365.016805832\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "model = GMM(n_components = 10, covariance_type =\"diag\")\n",
    "model.fit(data_fashion_training)\n",
    "t= model.score(data_fashion_training)\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30081468600940042"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import completeness_score\n",
    "prediction = model.predict(data_fashion_training)\n",
    "completeness_score(data_fashion_lable, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.42381427588\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "##The “mnist_train_fashion.csv” is downloaded from webpage of this link : https://www.kaggle.com/zalando-research/fashionmnist\n",
    "## here we only use the training data set for running the program\n",
    "\n",
    "# data_array_fashion is to store the training data\n",
    "spam = []\n",
    "with open(\"/Users/deshenghu/Dropbox/Dataset_CS6220/spambase/spambase.data\") as t:\n",
    "    for row in t:\n",
    "        spam.append(list(map(float, row.replace(\"\\n\", \"\").split(\",\"))))\n",
    "\n",
    "spam = np.matrix(spam)\n",
    "\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "model = GMM(n_components = 2, covariance_type =\"diag\")\n",
    "model.fit(spam)\n",
    "t= model.score(spam)\n",
    "print(t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
